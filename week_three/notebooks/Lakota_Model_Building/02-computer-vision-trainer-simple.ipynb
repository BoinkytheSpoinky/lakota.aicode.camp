{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision Simplified Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is modified from the `00-computer-vision-trainer.ipynb` notebook and has the explanation text removed\n",
    "\n",
    "The basic steps we'll take are:\n",
    "\n",
    "1. Importing our collected, organized, and cleaned images\n",
    "1. Fine-tune a pretrained neural network model to take images as inputs and output category labels\n",
    "1. Examining our output and deciding if we're happy with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP HERE, THIS IS THE BASE TRAINER, MAKE A COPY AND DO YOUR WORK THERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what you want to do for this training here:\n",
    "\n",
    "Item Transforms:\n",
    "\n",
    "Pre-Trained Model: \n",
    "\n",
    "Batch Size:  \n",
    "\n",
    "Validation Size: \n",
    "\n",
    "Epochs: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 0: Ensure you are running this notebook within a Docker Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/workspace/data/lakota_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Ensure you have spectrogram images\n",
    "\n",
    "The cell below will let you know what directories and file numbers are available in `/workspace/data/lakota_data`. This value should be assigned in an earlier cell for the variable `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(path):\n",
    "    print(f\"'{path}' is not a valid directory.\")\n",
    "else:\n",
    "    print(f\"Scanning directory: {path}\\n\")\n",
    "    for entry in os.scandir(path):\n",
    "        if entry.is_dir():\n",
    "            subdir_path = entry.path\n",
    "            file_count = sum(\n",
    "                1 for item in os.scandir(subdir_path) if item.is_file()\n",
    "            )\n",
    "            print(f\"{entry.name}/ â€” {file_count} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train an initial model so that we clean our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a model. More information about pretrained models, and others that you may want to use instead of `resnet34.a1_in1k` can be found at  \n",
    "[https://www.kaggle.com/code/jhoward/which-image-models-are-best](https://www.kaggle.com/code/jhoward/which-image-models-are-best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three cells below will support you in choosing a pre-trained model to use. If you're ok with using the default model of `resnet34.a1_in1k`, or already have one that you want to use, you can skip to the `DataBlock` cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('resnet*', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name\n",
    "model_name = 'resnet34.a1_in1k'\n",
    "\n",
    "# Create the model instance\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "# Retrieve the default configuration\n",
    "default_cfg = model.default_cfg\n",
    "print(default_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whichever model you choose, ensure that the `item_tfms` resize value matches the `'input_size'` in the information above. For the `'resnet34.a1_in1k'` model, the input size is `(3, 224, 224)` and so we need to ensure that the value below for `item_tfms` is:  \n",
    "  \n",
    "`item_tfms=Resize(224, 'squish')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(224, 'squish'),\n",
    "    batch_tfms=[]#We don't want to transform our spectrograms, leave this line alone\n",
    ").dataloaders(path, bs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: The batch size above (set by `bs=50`) cannot be higher than the number of image files you have.**\n",
    "\n",
    "If the batch size is too high, you will see an error for the cell below that says  \n",
    "`ValueError: This DataLoader does not contain any batches`.  \n",
    "\n",
    "Reduce the `bs` value above in order to overcome this issue.\n",
    "\n",
    "If you feel the batch size is good, save it in the cell below, we will use this in the longer training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 50 #this should match the value you have in the DataLoader above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=8, nrows=2, ncols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, model_name, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find() # find the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00100000004749745134 # use the value from the lr_find() method above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_training_epochs = 2\n",
    "learn.fine_tune(initial_training_epochs, base_lr=learning_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of this initial training is to ensure that the longer model training below will work correctly.\n",
    "\n",
    "**NOTE: If you get an error that states `RuntimeError: CUDA error: out of memory`, reduce the batch size value `bs=` in the `dataloaders()` parameters above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Let's see how our model did and what it had the most difficulty with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(normalize=True, title='Confusion Matrix', figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Now We Train A Model Using What We've Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameter of your training\n",
    "\n",
    "Naming convention: purpose_modelname_errorrate\n",
    "\n",
    "What the model does?\n",
    "What the model used?\n",
    "How good is the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#first set how often the model should save a checkpoint file, these will be stored as .pth files, not .pkl\n",
    "# not that .pth files will contain the model architecture, whereas .pkl files do not, which means .pth files are much larger in size\n",
    "\n",
    "last_epoch_save = 0 # leave this value as zero if you are starting over from cleaned data\n",
    "\n",
    "save_after_this_many_epochs = 5 # a .pth checkpoint file will be created every 5 epochs\n",
    "\n",
    "model = model_name # this was set above\n",
    "\n",
    "path = path # ensure this points to your data\n",
    "\n",
    "# Define the number of additional epochs you want to train for\n",
    "\n",
    "additional_epochs = 10  # Set the total number of epochs to run in the cell below\n",
    "\n",
    "learning_rate = learning_rate # use the value from the lr_find() method above\n",
    "\n",
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(224, 'squish'),#RandomResizedCrop(224, min_scale=0.3),\n",
    "    batch_tfms=[]\n",
    ").dataloaders(path, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.callback.core import Callback\n",
    "from fastai.learner import load_learner\n",
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "# SaveModelCallback will be triggered on each epoch, The default is 10 epochs, but you can set the amount using the save_after_this_many_epochs variable\n",
    "class SaveModelCallback(Callback):\n",
    "    def __init__(self, every=10, path='model', last_epoch_save=0):\n",
    "        self.every = every\n",
    "        self.path = path\n",
    "        self.last_epoch_save = last_epoch_save\n",
    "\n",
    "    def after_epoch(self):\n",
    "        \"Save the model every `self.every` epochs\"\n",
    "        if (self.epoch + 1) % self.every == 0:\n",
    "            self.learn.save(f'{self.path}_epoch{self.epoch + (1+self.last_epoch_save)}')\n",
    "\n",
    "# Define your data recover function, this function will return .pkl model from one of your checkpoint save files in the .pth format\n",
    "# path = the path to your data (e.g. /workspace/data/TRAINING_DATA), path_to_pth_model = the path to your last saved .pth file\n",
    "def recover_dl_from_pth(path, path_to_pth_model):\n",
    "    dls = ImageDataLoaders.from_folder(path)\n",
    "    learn = cnn_learner(dls, model) # be sure to use the same pretrained model here that you did for previous training, the model variable set above\n",
    "    learn.load(path_to_pth_model)  # Load the model from the .pth file into the learn variable\n",
    "    return learn # return the learn variable\n",
    "\n",
    "# Load the previously trained model\n",
    "recover_from_pth_file = False\n",
    "\n",
    "if(recover_from_pth_file):\n",
    "    # The code below will create a learner recovered from a checkpoint save\n",
    "    # You will want to make sure that the pretrained model in recover_dl_from_pth() the same as what was used for fine tuning earlier\n",
    "    learn_long = recover_dl_from_pth(path, '/workspace/models/model_epochEPOCH_NUM_HERE_TO_GET_TO_CORRECT_FLE.pth')\n",
    "else:\n",
    "    # This code will start at 0 or recover from a .pkl file\n",
    "    if(last_epoch_save > 0):\n",
    "        previous_model_path = '/workspace/models/MODEL_FILENAME.pkl'  # replace with your actual model path\n",
    "        learn_long = load_learner(previous_model_path) #note that this is creating a different learner than the one we used above\n",
    "    else:\n",
    "        learn_long = vision_learner(dls, model, metrics=error_rate) # create the learner\n",
    "    # Ensure data loaders are set up\n",
    "    learn_long.dls = dls # path is the path to our data, which was set earlier\n",
    "\n",
    "# Instantiate the custom callback\n",
    "# modify last_epoch_save to be the number of epochs the model was trained up to\n",
    "save_model_callback = SaveModelCallback(every=save_after_this_many_epochs, path='/workspace/models/model', last_epoch_save = last_epoch_save)\n",
    "\n",
    "# Continue training the model with the custom callback\n",
    "learn_long.fine_tune(additional_epochs, base_lr=learning_rate, cbs=[save_model_callback])\n",
    "\n",
    "# Save the updated model at the end\n",
    "updated_model_path = f'/workspace/models/model_epoch{(last_epoch_save+additional_epochs)}.pkl'\n",
    "learn_long.export(updated_model_path)\n",
    "\n",
    "print(\"Training completed and model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_long = ClassificationInterpretation.from_learner(learn_long)\n",
    "interp_long.plot_confusion_matrix(normalize=True, title='Confusion Matrix', figsize=(12, 12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
