{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729bff69",
   "metadata": {},
   "source": [
    "## How do we convert our audio files to image files?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843006c0",
   "metadata": {},
   "source": [
    "We should now have some augmented audio files in `/workspace/data/augmented_audio`, but our model training notebooks work with images. This notebook will create these audio files for us and place them in a folder named `lakota_data`.  \n",
    "  \n",
    "The cell below provide the tools to create the necessary images. `Librosa` is a popular library for carrying out this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d293e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3775cd81",
   "metadata": {},
   "source": [
    "The function below `audio_to_melspectrogram_image()` is the function that will create the images for us, and we have some options that you may want to modify that will influence the image that gets produced.  \n",
    "\n",
    "In particular, the parameter called `cmap` in the line  \n",
    "`librosa.display.specshow(mel_db, sr=sr, fmax=fmax, cmap='viridis')`.  \n",
    "The `cmap` parameter controls the color map of the images and an explanation of the options is below.  \n",
    "  \n",
    "The default option selected is `cmap='viridis'`, but you can use any of the options below to create different spectrograms for your model training.  \n",
    "\n",
    "üîµ Perceptually Uniform Colormaps (Good for ML and clarity)\n",
    " - 'viridis' ‚Äì (default you‚Äôre using) good contrast, colorblind-friendly.  \n",
    " - 'plasma' ‚Äì vibrant and high-contrast.  \n",
    " - 'inferno' ‚Äì dark background, high dynamic range.  \n",
    " - 'magma' ‚Äì smoother than inferno, darker background.  \n",
    " - 'cividis' ‚Äì designed for color vision deficiency.  \n",
    "\n",
    "üåà Traditional/Classic Colormaps\n",
    " - 'jet' ‚Äì very colorful, but not perceptually uniform (can mislead perception).  \n",
    " - 'hot' ‚Äì black to red to yellow to white.  \n",
    " - 'cool' ‚Äì cyan to magenta gradient.  \n",
    " - 'spring', 'summer', 'autumn', 'winter' ‚Äì seasonal gradient palettes.  \n",
    "\n",
    "‚ö´ Grayscale and Inverted\n",
    " - 'gray' ‚Äì grayscale (black = low, white = high).  \n",
    " - 'bone', 'binary', 'gist_yarg' ‚Äì variations of grayscale.  \n",
    " - 'Greys', 'Purples', 'Blues', 'Oranges', 'Reds' ‚Äì monochrome ramps.  \n",
    " - 'copper', 'pink', 'coolwarm' ‚Äì alternative tones with visual flair.  \n",
    "\n",
    "üîÅ Inverted Colormaps\n",
    "\n",
    "You can invert any colormap by appending `_r`, e.g.:\n",
    " - 'viridis_r'  \n",
    " - 'inferno_r'  \n",
    " - 'gray_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3fde95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_melspectrogram_image(audio_path, output_path, sr=16000, n_mels=128, fmax=8000):\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    plt.figure(figsize=(2.24, 2.24))  # For 224x224 px output\n",
    "    librosa.display.specshow(mel_db, sr=sr, fmax=fmax, cmap='viridis')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6c7f0",
   "metadata": {},
   "source": [
    "The cell below will take our augmented audio files and produce all of the images that we will need for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411d8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/workspace/data/augmented_audio\"\n",
    "output_dir = \"/workspace/data/lakota_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "input_root = Path(input_dir)\n",
    "input_files = list(input_root.rglob(\"*.wav\"))\n",
    "print(f\"Found {len(input_files)} audio files in {input_dir}\")\n",
    "\n",
    "for root, _, files in os.walk(input_dir):\n",
    "    for fname in files:\n",
    "        if fname.endswith(\".wav\"):\n",
    "            rel_path = os.path.relpath(root, input_dir)  # e.g., 'red' or 'yellow'\n",
    "            input_path = os.path.join(root, fname)\n",
    "\n",
    "            # Construct output path with same subdir structure\n",
    "            target_dir = os.path.join(output_dir, rel_path)\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "            output_path = os.path.join(target_dir, fname.replace(\".wav\", \".png\"))\n",
    "            audio_to_melspectrogram_image(input_path, output_path)\n",
    "            \n",
    "print(f\"\\n‚úÖ Done. Augmented files saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce86df",
   "metadata": {},
   "source": [
    "And finally, the cell below will create a zip file of all the data and place it in `/workspace/data` for us. This is useful for backing up and possibly sharing our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c102e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"/workspace/data/lakota_data\", 'zip', \"/workspace/data/lakota_data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
